\documentclass[a4paper]{article}
\usepackage[top=1in,bottom=1in,left=1in,right=1in]{geometry}
\usepackage{times}
\usepackage{amssymb}
\usepackage{mathtools}	% pulls in amsmath
	\mathtoolsset{centercolon}
\usepackage{tikz}
	\usetikzlibrary{automata}
	\usepackage{tikz-qtree}
\usepackage{mathpartir}
\usepackage{amsthm}
\usepackage{amsxtra}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{semantic}
	\reservestyle{\declarevars}{\texttt}
	\reservestyle{\declareops}{\texttt}
	\reservestyle{\declarestates}{\text}
\usepackage{color}
\usepackage{listings}
\usepackage{mathtools}
\usepackage{enumerate}

\newtheorem{theorem}{Theorem}

\newtheorem{myexample}{\textbf{Example}}
\newtheorem{mylemma}{\textbf{Lemma}}
\newtheorem{myproof}{\textbf{Proof}}
\newtheorem{myinvariant}{\textbf{Invariant}}
\newtheorem{mytheorem}{\textbf{Theorem}}
\newtheorem{mycorollary}{\textbf{Corollary}}
\newtheorem{myapproach}{Approach}
\newtheorem{myproperty}{Property}
\newtheorem{mydefinition}{Definition}

\newtheorem{mycase}{Case}

\lstset{ %
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
  basicstyle=\small,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
 % frame=single,                    % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  columns=fullflexible,	% not monospace
  keywordstyle=\color{blue},       % keyword style
  language=Octave,                 % the language of the code
  morekeywords={then, end, and, or, assign, increment, decrement, jump, jump_if, store, *, +},            % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=1,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,                       % sets default tabsize to 2 spaces
  title=\lstname,                  % show the filename of files included with \lstinputlisting; also try caption instead of title
  mathescape
}

\DeclareMathOperator{\prob}{prob}
\DeclareMathOperator{\key}{key}
\newcommand*{\floor}[1]{\left\lfloor{#1}\right\rfloor}
\newcommand*{\ceil}[1]{\left\lceil{#1}\right\rceil}
\newcommand{\any}{{\rule[-.2ex]{1ex}{.4pt}}}	% Less hideous than \_.
\newcommand{\RR}{\mathbb{R}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\RP}{\RR_{\ge 0}}
\newcommand*{\dave}[1]{{\color{red}\textbf{PDS: #1}}}
\newcommand{\ie}{\emph{i.e.,} }
\newcommand{\eg}{\emph{e.g.,} }
\usepackage{hyperref}
\newcommand*{\figref}[1]{\hyperref[#1]{Figure~\ref*{#1}}}

\title{Exercise Sheet 3---Algorithms and Data Structures}
\author{Felipe Cerqueira \\ 2547787 \and David Swasey \\ 2542105}

\begin{document}

\maketitle

Tutorial time: Monday 14:00

\section{Exercise 1 (10 pts)}

\paragraph{Answer:}

\section{Exercise 2 (10 pts)}

One of the most famous balanced search trees is the \emph{red-black tree}.
This is a binary search tree where each edge is either colored black or red.
The \emph{black depth} of a node $v$ is the number of black edges on the path from the root to $v$.
The following invariants have to hold:
\begin{enumerate}[a)]
\item All leaves have the same black depth.
\item Edges incident to leaves are black.
\item No path from the root to a leaf contains two consecutive red edges.
\end{enumerate}

Explain how a $(2,4)$-tree can be transformed into a red-black tree and vice versa.
Assuming that elements are stored in the leaves of the red-black tree, give a procedure for inserting a new element in logarithmic time which corresonds to the insertion in $(2,4)$-trees.

\paragraph{Answer:}

First, some intuition:
Why do the red-black~(RB) invariants help?
The following lemma says that RB trees are balanced ``up to a factor of two''.

\begin{mylemma}
	For any node $v$ in an RB tree,
	\[
		S(v) \le 2L(v)
	\]
	where $L(v)$ (resp.\ $S(v)$) is the number of edges in a longest (resp.\ shortest) path from $v$ to a leaf.
\end{mylemma}

\begin{proof}
	Define $L'$ and $S'$ analogous to $L$ and $S$, but counting black edges only.
	By~(a), $L'(v) = S'(v)$.
	By~(c), $L'(v) \le 2L(v)$ (since the worst we can do is alternate red, black edges).
	By minimality, $S(v) \le S'(v)$.
	Thus $S(v) \le S'(v) = L'(v) \le 2L(v)$.
\end{proof}

Having demonstrated we understand your invariants, we feel free to change them!
We prefer to color nodes rather than edges:
A RB tree is a binary search tree where each node stores, in addition to its ordinary payload, a color (red or black).
These data satisfy three invariants:
\begin{enumerate}[A)]
\item Every path from the root to an empty node contains the same number of black nodes.
\item Empty nodes (\ie pointers to $\bot$) are black.
\item No red node has a red child.
\end{enumerate}
The two representations are isomorphic:
We can regard the color bit stored in a node as the color for the link to the node from its parent (or from the outside world, in the case of the root node).
We make this change because coloring nodes is more familiar to us.
It might help if one wants to implement RB trees.
(Pointers aren't always colorful, but nodes can always carry color bits.)

\begin{figure}
\[
	\begin{array}{c@{\qquad}c@{\qquad}c}
		\tikz{\Tree [.$s$ $c_1$ $c_2$ ]} & \tikz{\Tree [.{$s_1, s_2$} $c_1$ $c_2$ $c_3$ ]} & \tikz{\Tree[.{$s_1, s_2, s_3$} $c_1$ $c_2$ $c_3$ $c_4$ ]} \\[2\jot]
		\Downarrow & \Downarrow & \Downarrow \\[2\jot]
		\tikz{\Tree [.$s$ $c_1$ $c_2$ ]} & \tikz{\Tree [.$s_1$ $c_1$ [.\node[red]{$s_2$}; $c_2$ $c_3$ ] ]} & \tikz{\Tree [.$s_2$ [.$s_1$ $c_1$ $c_2$ ] [.$s_3$ $c_3$ $c_4$ ] ]}
	\end{array}
\]
\caption{%
	Turning $(2,4)$-trees into red-black trees.
	We color red nodes red.
}
\label{fig:torb}
\end{figure}

\paragraph{Turning a $(2,4)$-tree into a RB tree:}
We give the basic idea in \figref{fig:torb}.
In each case, the root is colored black and the black depth of the children $c_i$ is identical.
Thus the obvious recursive algorithm produces a RB tree.

\begin{figure}
\[
	\begin{array}{ccccc}
		&& \tikz{\Tree [.$a$ [.\node[red]{$b$}; $A$ $B$ ] [.\node[red]{$c$}; $C$ $D$ ] ]} \\
		&& \Downarrow \\
		\tikz{\Tree [.$a$ [.\node[red]{$b$}; $A$ $B$ ] [.$c$ $C$ $D$ ] ]} & \Rightarrow & \tikz{\Tree [.\node{$b, a, c$}; $A$ $B$ $C$ $D$ ]} & \Leftarrow & \tikz{\Tree [.$a$ [.$b$ $A$ $B$ ] [.\node[red]{$c$}; $C$ $D$ ] ]}
	\end{array}
\]
\caption{%
	Turning red-black trees into $(2,4)$ trees.
	We color red nodes red.
	We omit the case of a black node with black children (see the text).
}
\label{fig:to24}
\end{figure}

\paragraph{Turning a RB tree into a $(2,4)$-tree:}
Assume the root is black.
(If it's not, then color it black.
This does not violate the RB invariants.)
By~(C), we need not consider the case of red nodes with red children.
We show how to treat black nodes with red children in \figref{fig:to24}.
To deal with black nodes with black children, we turn the root into a single-splitter node, then recurse on the subtrees.
In each case, all subtrees have the same depth.
Thus the obvious recursive algorithm produces a $(2,4)$-tree.

\paragraph{RB tree insertion:}
The textbook algorithm for insertion into RB trees is structured just like insertion into (2,4)-trees:
Search for the spot to insert, drop in the new node, then patch the path back to the root, making local changes on the way up in order to re-establish the invariant.
In detail:
\begin{enumerate}
\item Create a new node, $v$, colored \emph{red}, to contain the element $e$ to be inserted.

\item Use binary search to find the the leaf node, $p$, that should be $v$'s parent.

\item If $\key(v) < \key(p)$, then $p.L \gets v$; otherwise $p.R \gets v$.

\item patch($v$).
(Discussed next.)

\end{enumerate}
By coloring the new node red, we preserved invariant~(A).
We changed one of $p$'s children from black to red ($\bot$ is black), so we have to worry about invariant~(C).

\begin{figure}
\[
	\begin{array}{ccccc}
		&& \tikz{\Tree [.$z$ [.\node[red]{$x$}; $A$ [.\node[red]{$y$}; $B$ $C$ ] ] $D$ ]} \\[2\jot]
		&& \Downarrow \\
		\tikz{\Tree [.$z$ [.\node[red]{$y$}; [.\node[red]{$x$}; $A$ $B$ ] $C$ ] $D$ ]} & \Rightarrow & \tikz{\Tree [.\node[red]{$y$}; [.$x$ $A$ $B$ ] [.$z$ $C$ $D$ ] ]} & \Leftarrow & \tikz{\Tree [.$x$ $A$ [.\node[red]{$y$}; $B$ [.\node[red]{$z$}; $C$ $D$ ] ] ]} \\[2\jot]
		&& \Uparrow \\[2\jot]
		&& \tikz{\Tree [.$x$ $A$ [.\node[red]{$z$}; [.\node[red]{$y$}; $B$ $C$ ] $D$ ] ]}
	\end{array}
\]
\caption{%
	Moving a red-red violation toward the root (part of RB tree insertion).
	Here, $x$, $y$, and $z$ represent nodes that are examined by patch;
	$A$, $B$, $C$, and $D$ represent arbitrary subtrees (pointers pushed around by patch);
	and we color red nodes red.
	(Attribution: Adapted from Figure~3.5 in Chris Okasaki's {\it Purely functional data structures,} Cambridge University Press, 1998.)
}
\label{fig:rbpatch}
\end{figure}

In patch($v$), we permit at most one red-red violation at a time, and we push it toward the root.
Once we reach the root, we color the root black, avoiding any red-red violations while preserving invariant~(A).
In detail, patch($v$) works by following parent pointers, pattern-matching against the four red-red cases in~\figref{fig:rbpatch}, and rewriting acording to the figure.
(Optimization:
If, on the way up to the root, patch sees no red-red case, then it can stop.
Further optimizations are possible by considering eight rather than four cases.)

\paragraph{Practical advice:}
If you need persistent finite sets or maps, then RB trees are great.
If you don't care about persistence, then use splay trees (if you can tolerate amortized complexity) or hash tables (if you can tolerate writing hash functions rather than comparison functions).
They're faster.
Avoid $(2,4)$-trees; the constants are ridiculous.
Their only benefit, in the second author's opinon, is that they generalize to B-trees, where they really shine as an on-disk data structure.
All flavors of HFS, for example, store metadata in B-trees.

\section{Exercise 3(10 pts)}

Change the splay by replacing the zig-zig rotation according to the following picture:
\[
	\tikz{\Tree [.$z$ [.$y$ [.$x$ $A$ $B$ ] $C$ ] $D$ ]} \Rightarrow \tikz{\Tree [.$x$ $A$ [.$z$ [.$y$ $B$ $C$ ] $D$ ] ]}
\]
%$x$ is left child of $y$, which is left child of $z$. Apply ${rotate}(x), {rotate}(x)$.


\noindent Explain why the proof that a splay operation has logarithmic amortized complexity does not carry over to this case.

\paragraph{Answer:}

We want to bound the resulting value of $\mu$ for the nodes involved in the operation:

\begin{align*}
\mu'(x) + \mu'(y) + \mu'(z) - \mu(x) - \mu(y) - \mu(z)
\end{align*}

But from the state of the tree, we don't have the guarantee that $\mu'(x) = \mu(z)$ from the original zig-zig operation. Since sub-trees $C$ and $D$ are farther from $x$ by 1 edge, we can only infer that $\mu'(x) \le \mu(z) + 1$.

\begin{align*}
\mu'(x) + \mu'(y) + \mu'(z) - \mu(x) - \mu(y) - \mu(z) \\
\le \mu(z) + 1 + \mu'(y) + \mu'(z) - \mu(x) - \mu(y) - \mu(z) \\
= 1 + \mu'(y) + \mu'(z) - \mu(x) - \mu(y) \\
= 1 + (\mu'(y) - \mu(x)) + (\mu'(z)  - \mu(y)) \\
\le 1 + (\mu'(x) - \mu(x)) + (\mu'(x)  - \mu(x)) \\
= 1 + 2\cdot (\mu'(x) - \mu(x))
\end{align*}

This leaves us with $\mu'(x) - \mu(x) - 1$ credits left to pay for the constant number of operations. However, there can be a case where $\mu'(x) - \mu(x) = 1$ (for example, if $\mu(B) = \mu(D)$). In that case we would have 0 credits for the remaining operations, which is insufficient.

\section{Exercise 4 (10 pts)}

A major advantage of binary heaps is that they can be represented by an array, Assume the heap with $n$ elements is stored in an unbounded array $A$. Rephrase ${insert}$, ${remove}$, and ${build}$ for this array representation.

\paragraph{Answer:}

\section{Exercise 5 (10 pts)}

\paragraph{a) } Argue that the implementation of ${sift\_down}$ as given in the lecture requires $2 \log n$ comparison of keys in the worst case.

\paragraph{Answer:} First, note that there is one comparison to compute smallest child and one in the ${if}$ statement.
 
The worst-case happens if we compute ${sift\_down}({root})$ and the comparison ${key}(v) < {key}(w)$ is always false (else case). Then, we require 2 comparisons for every node in some path from the root to a leaf, that is, twice the height of the tree:  $2 \log n$.

\paragraph{b) } Give an alternative implementation that requires only $\log n + O(\log \log n)$ comparisons.

\paragraph{Answer:}


\end{document}
